# Chat Web

## 基本介绍

Chat Web提供了一个网页界面，让用户可以通过类似线上聊天的方式使用MindFormers大语言模型（LLM）推理能力。

## [Chat Web支持模型](../model_support_list.md#chat-web支持列表)

## 使用方式

### 单卡启动

示例命令如下，将会启动一个网页app，使用glm_6b模型进行回答生成。

```bash
python run_chat_web.py --device_target Ascend \
                       --device_id 0 \
                       --model glm_6b \
                       --tokenizer glm_6b \
                       --checkpoint_path /path/to/glm_6b.ckpt \
                       --seq_length 512 \
                       --use_past False \
                       --host 0.0.0.0 \
                       --port 7860
```

参数定义如下：

* **device_target** (str) - 表示要运行的目标设备，取值为`Ascend/CPU`。如果所安装的MindSpore版本不支持`Ascend`，将运行在CPU上。默认值：`Ascend`。
* **device_id** (int) - 表示要运行的卡，取值为`[0,8)`。该值只在`device_target==Ascend`时生效。默认值：`0`。
* **model** (str) - 表示用来生成回答的模型的名称，取值见上节。
* **tokenizer** (str) - 表示用来编解码输入输出的分词器的名称，取值见上节。
* **checkpoint_path** (str) - 表示加载的模型权重文件路径，此参数缺省时将会下载模型默认的权重文件，默认值：`None`。
* **seq_length** (int) - 表示模型中的序列长度。默认值：`512`。
* **use_past** (bool) - 表示是否使用增量推理。默认值：`False`。
* **host** (str) - 表示web服务运行的host ip。设置为`0.0.0.0`可远程访问。默认值：`127.0.0.1`。
* **port** (int) - 表示web服务运行的端口。此参数缺省时端口将会设置为`7860`，如果该端口被占用将会向后顺延，直至找到可用端口。默认值：`None`。

### 多卡启动

暂不支持

### 网页使用

当`--port`参数缺省时网页app将会默认运行在`7860`端口，如果默认端口被占用将会向后顺延，直至找到可用端口。

通过浏览器访问Chat Web网页地址

> 如果服务启动在本地，即配置了`--host`为`127.0.0.1`，则访问`http://127.0.0.1:7860`或`http://localhost:7860`
>
> 如果服务启动在远程，即配置了`--host`为`0.0.0.0`，假设服务器IP地址为`12.23.34.45`，则访问`http://12.23.34.45:7860`

在输入框中输入文字，点击***提交***按钮，稍等片刻后屏幕上将会显示LLM的回答。点击***清除***按钮可以清空聊天记录。

#### 配置项

聊天界面右侧提供了若干配置项，可以在点击提交按钮前自行进行配置，每次输入将会实时生效。目前提供的配置项如下：

* **sampling** (开关) - 打开表示使用采样；关闭则表示使用贪心解码。打开后可以调整下述**top k**和**top p**。

    * **top k** (滑块) - 从前k个可能性最大的候选词中采样。取值范围：`[0,10]`。
    * **top p** (滑块) - 从可能性加起来为p的候选词中采样。取值范围：`[0,1]`。
    * **temperature** (输入框) - 用来调节候选词的可能性得分。取值范围：`(0,∞)`。

* **repetition penalty** (输入框) - 重复惩罚因子。`1.0`表示无惩罚。取值范围：`(0,∞)`。

* **max length** (输入框) - 输入与回答的最大长度，不能超过模型的`seq_length`（注意：多轮对话时，输入将包括前几轮对话）。取值范围：`(输入长度,seq_length)`。

* **prompt** (输入框) - 提示词模板，与输入拼接后传进模型。输入框下方提供了一些样例模板，用户也可以输入自定义的模板，需要包含占位符`{}`，代表替换输入的位置。

> 每次启动时，配置项将会设置为模型默认的状态。